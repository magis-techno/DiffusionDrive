{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# æ¨¡å‹æ¨ç†ä¸å¯è§†åŒ–æ•™ç¨‹\n",
        "\n",
        "æœ¬æ•™ç¨‹å±•ç¤ºå¦‚ä½•ï¼š\n",
        "1. åŠ è½½é¢„è®­ç»ƒçš„DiffusionDriveæ¨¡å‹\n",
        "2. è¿›è¡Œå•å¸§æ¨ç†\n",
        "3. ä½¿ç”¨ç°æœ‰çš„å¯è§†åŒ–åŠŸèƒ½å±•ç¤ºç»“æœ\n",
        "4. å¯¹æ¯”æ¨¡å‹é¢„æµ‹ä¸çœŸå®è½¨è¿¹\n",
        "\n",
        "## ç¯å¢ƒè®¾ç½®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, Any\n",
        "\n",
        "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# å¯¼å…¥å¿…è¦çš„æ¨¡å—\n",
        "import hydra\n",
        "from hydra.utils import instantiate\n",
        "from omegaconf import DictConfig\n",
        "\n",
        "from navsim.common.dataloader import SceneLoader\n",
        "from navsim.common.dataclasses import SceneFilter, SensorConfig, Scene\n",
        "from navsim.agents.abstract_agent import AbstractAgent\n",
        "from navsim.visualization.plots import plot_bev_with_agent, plot_bev_frame\n",
        "\n",
        "# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆè¯·æ ¹æ®æ‚¨çš„ç¯å¢ƒä¿®æ”¹ï¼‰\n",
        "if not os.getenv(\"OPENSCENE_DATA_ROOT\"):\n",
        "    os.environ[\"OPENSCENE_DATA_ROOT\"] = \"/path/to/your/data\"  # è¯·ä¿®æ”¹ä¸ºæ‚¨çš„æ•°æ®è·¯å¾„\n",
        "\n",
        "print(\"ç¯å¢ƒè®¾ç½®å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. æ•°æ®åŠ è½½å™¨è®¾ç½®\n",
        "\n",
        "é¦–å…ˆè®¾ç½®æ•°æ®åŠ è½½å™¨ï¼Œç”¨äºåŠ è½½æµ‹è¯•åœºæ™¯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# é…ç½®æ•°æ®åŠ è½½\n",
        "SPLIT = \"mini\"  # ä½¿ç”¨miniæ•°æ®é›†è¿›è¡Œæµ‹è¯•\n",
        "FILTER = \"all_scenes\"\n",
        "\n",
        "# åˆå§‹åŒ–åœºæ™¯è¿‡æ»¤å™¨\n",
        "hydra.initialize(config_path=\"../navsim/planning/script/config/common/scene_filter\", version_base=None)\n",
        "cfg = hydra.compose(config_name=FILTER)\n",
        "scene_filter: SceneFilter = instantiate(cfg)\n",
        "\n",
        "# è®¾ç½®æ•°æ®è·¯å¾„\n",
        "openscene_data_root = Path(os.getenv(\"OPENSCENE_DATA_ROOT\"))\n",
        "\n",
        "# åˆ›å»ºåœºæ™¯åŠ è½½å™¨\n",
        "scene_loader = SceneLoader(\n",
        "    openscene_data_root / f\"navsim_logs/{SPLIT}\",\n",
        "    openscene_data_root / f\"sensor_blobs/{SPLIT}\",\n",
        "    scene_filter,\n",
        "    sensor_config=SensorConfig.build_all_sensors(),\n",
        ")\n",
        "\n",
        "print(f\"æ•°æ®åŠ è½½å™¨è®¾ç½®å®Œæˆï¼Œå¯ç”¨åœºæ™¯æ•°é‡: {len(scene_loader.tokens)}\")\n",
        "hydra.core.global_hydra.GlobalHydra.instance().clear()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. æ¨¡å‹åŠ è½½ä¸åŒ…è£…å™¨\n",
        "\n",
        "åˆ›å»ºä¸€ä¸ªAgentåŒ…è£…å™¨ï¼Œç”¨äºåŠ è½½å’Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelInferenceAgent(AbstractAgent):\n",
        "    \"\"\"\n",
        "    æ¨¡å‹æ¨ç†ä»£ç†åŒ…è£…å™¨\n",
        "    å°†è®­ç»ƒå¥½çš„æ¨¡å‹åŒ…è£…æˆç¬¦åˆAbstractAgentæ¥å£çš„ç±»\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_type=\"diffusiondrive\", checkpoint_path=None):\n",
        "        super().__init__()\n",
        "        self.model_type = model_type\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "        self.model = None\n",
        "        self.config = None\n",
        "        \n",
        "        if checkpoint_path:\n",
        "            self._load_model()\n",
        "    \n",
        "    def _load_model(self):\n",
        "        \"\"\"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹\"\"\"\n",
        "        try:\n",
        "            if self.model_type == \"diffusiondrive\":\n",
        "                from navsim.agents.diffusiondrive.transfuser_agent import TransfuserAgent\n",
        "                from navsim.agents.diffusiondrive.transfuser_config import TransfuserConfig\n",
        "                \n",
        "                # åŠ è½½é…ç½®\n",
        "                self.config = TransfuserConfig()\n",
        "                \n",
        "                # åˆ›å»ºagentå¹¶åŠ è½½æ£€æŸ¥ç‚¹\n",
        "                agent = TransfuserAgent(self.config)\n",
        "                checkpoint = torch.load(self.checkpoint_path, map_location='cpu')\n",
        "                \n",
        "                # åŠ è½½æ¨¡å‹æƒé‡\n",
        "                if 'state_dict' in checkpoint:\n",
        "                    agent.load_state_dict(checkpoint['state_dict'])\n",
        "                else:\n",
        "                    agent.load_state_dict(checkpoint)\n",
        "                \n",
        "                agent.eval()\n",
        "                self.model = agent\n",
        "                \n",
        "            elif self.model_type == \"transfuser\":\n",
        "                from navsim.agents.transfuser.transfuser_agent import TransfuserAgent\n",
        "                from navsim.agents.transfuser.transfuser_config import TransfuserConfig\n",
        "                \n",
        "                self.config = TransfuserConfig()\n",
        "                agent = TransfuserAgent(self.config)\n",
        "                checkpoint = torch.load(self.checkpoint_path, map_location='cpu')\n",
        "                \n",
        "                if 'state_dict' in checkpoint:\n",
        "                    agent.load_state_dict(checkpoint['state_dict'])\n",
        "                else:\n",
        "                    agent.load_state_dict(checkpoint)\n",
        "                    \n",
        "                agent.eval()\n",
        "                self.model = agent\n",
        "            \n",
        "            print(f\"æˆåŠŸåŠ è½½ {self.model_type} æ¨¡å‹ï¼\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
        "            print(\"å°†ä½¿ç”¨ç®€å•çš„å¸¸é€Ÿåº¦æ¨¡å‹è¿›è¡Œæ¼”ç¤º\")\n",
        "            self._use_fallback_model()\n",
        "    \n",
        "    def _use_fallback_model(self):\n",
        "        \"\"\"å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„åŸºçº¿æ¨¡å‹\"\"\"\n",
        "        from navsim.agents.constant_velocity_agent import ConstantVelocityAgent\n",
        "        self.model = ConstantVelocityAgent()\n",
        "        self.model_type = \"constant_velocity\"\n",
        "        print(\"ä½¿ç”¨å¸¸é€Ÿåº¦æ¨¡å‹ä½œä¸ºæ¼”ç¤º\")\n",
        "    \n",
        "    def compute_trajectory(self, agent_input, scene=None):\n",
        "        \"\"\"è®¡ç®—è½¨è¿¹é¢„æµ‹\"\"\"\n",
        "        if self.model is None:\n",
        "            self._use_fallback_model()\n",
        "        \n",
        "        # æ ¹æ®æ¨¡å‹ç±»å‹è°ƒç”¨ç›¸åº”çš„æ¨ç†æ–¹æ³•\n",
        "        if hasattr(self.model, 'requires_scene') and self.model.requires_scene and scene is not None:\n",
        "            return self.model.compute_trajectory(agent_input, scene)\n",
        "        else:\n",
        "            return self.model.compute_trajectory(agent_input)\n",
        "\n",
        "# åˆ›å»ºæ¨ç†ä»£ç†å®ä¾‹\n",
        "# è¯·å°†checkpoint_pathä¿®æ”¹ä¸ºæ‚¨çš„æ¨¡å‹è·¯å¾„\n",
        "checkpoint_path = None  # ä¾‹å¦‚: \"/path/to/your/model.pth\"\n",
        "inference_agent = ModelInferenceAgent(\n",
        "    model_type=\"diffusiondrive\", \n",
        "    checkpoint_path=checkpoint_path\n",
        ")\n",
        "\n",
        "print(f\"æ¨ç†ä»£ç†åˆ›å»ºå®Œæˆï¼Œæ¨¡å‹ç±»å‹: {inference_agent.model_type}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. é€‰æ‹©æµ‹è¯•åœºæ™¯\n",
        "\n",
        "ä»æ•°æ®é›†ä¸­é€‰æ‹©ä¸€ä¸ªåœºæ™¯è¿›è¡Œæµ‹è¯•\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# éšæœºé€‰æ‹©ä¸€ä¸ªåœºæ™¯\n",
        "token = np.random.choice(scene_loader.tokens)\n",
        "print(f\"é€‰æ‹©çš„åœºæ™¯token: {token}\")\n",
        "\n",
        "# åŠ è½½åœºæ™¯\n",
        "scene = scene_loader.get_scene_from_token(token)\n",
        "agent_input = scene_loader.get_agent_input_from_token(token)\n",
        "\n",
        "print(f\"åœºæ™¯ä¿¡æ¯:\")\n",
        "print(f\"  - å†å²å¸§æ•°: {scene.scene_metadata.num_history_frames}\")\n",
        "print(f\"  - æœªæ¥å¸§æ•°: {scene.scene_metadata.num_future_frames}\")\n",
        "print(f\"  - æ€»å¸§æ•°: {len(scene.frames)}\")\n",
        "print(f\"  - åœºæ™¯ç±»å‹: {scene.scene_metadata.scenario_type}\")\n",
        "print(f\"  - æ—¥å¿—åç§°: {scene.scene_metadata.log_name}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. åŸºç¡€å¯è§†åŒ–ï¼šBEVè½¨è¿¹å¯¹æ¯”\n",
        "\n",
        "ä½¿ç”¨ç°æœ‰çš„`plot_bev_with_agent`å‡½æ•°è¿›è¡Œè½¨è¿¹å¯¹æ¯”å¯è§†åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºBEVè½¨è¿¹å¯¹æ¯”å›¾\n",
        "fig, ax = plot_bev_with_agent(scene, inference_agent)\n",
        "\n",
        "# æ·»åŠ æ ‡é¢˜å’Œè¯´æ˜\n",
        "plt.title(f\"è½¨è¿¹å¯¹æ¯” - {inference_agent.model_type.upper()}æ¨¡å‹\\n\" + \n",
        "          f\"åœºæ™¯: {scene.scene_metadata.scenario_type}\\n\" +\n",
        "          f\"ç»¿è‰²: äººç±»é©¾é©¶è½¨è¿¹, çº¢è‰²: AIé¢„æµ‹è½¨è¿¹\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"BEVè½¨è¿¹å¯¹æ¯”å›¾å·²ç”Ÿæˆï¼\")\n",
        "print(\"å›¾ä¾‹è¯´æ˜:\")\n",
        "print(\"  - ç»¿è‰²è½¨è¿¹: äººç±»é©¾é©¶å‘˜çš„çœŸå®è½¨è¿¹\")\n",
        "print(\"  - çº¢è‰²è½¨è¿¹: AIæ¨¡å‹çš„é¢„æµ‹è½¨è¿¹\")\n",
        "print(\"  - ç°è‰²åŒºåŸŸ: é“è·¯å’Œå¯è¡Œé©¶åŒºåŸŸ\")\n",
        "print(\"  - å½©è‰²æ–¹æ¡†: å…¶ä»–è½¦è¾†å’Œéšœç¢ç‰©\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. è¯¦ç»†è½¨è¿¹åˆ†æ\n",
        "\n",
        "è·å–å’Œåˆ†æè½¨è¿¹çš„æ•°å€¼ä¿¡æ¯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è·å–è½¨è¿¹æ•°æ®\n",
        "human_trajectory = scene.get_future_trajectory()\n",
        "agent_trajectory = inference_agent.compute_trajectory(agent_input, scene)\n",
        "\n",
        "print(\"è½¨è¿¹åˆ†æ:\")\n",
        "print(f\"  - äººç±»è½¨è¿¹ç‚¹æ•°: {len(human_trajectory.poses)}\")\n",
        "print(f\"  - AIé¢„æµ‹è½¨è¿¹ç‚¹æ•°: {len(agent_trajectory.poses)}\")\n",
        "print(f\"  - é‡‡æ ·é—´éš”: {human_trajectory.trajectory_sampling.interval_length:.2f}ç§’\")\n",
        "print(f\"  - é¢„æµ‹æ—¶é•¿: {human_trajectory.trajectory_sampling.time_horizon:.1f}ç§’\")\n",
        "\n",
        "# è®¡ç®—è½¨è¿¹ç»Ÿè®¡ä¿¡æ¯\n",
        "human_poses = np.array(human_trajectory.poses)\n",
        "agent_poses = np.array(agent_trajectory.poses)\n",
        "\n",
        "# è®¡ç®—ä½ç½®å·®å¼‚ï¼ˆæ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰\n",
        "min_length = min(len(human_poses), len(agent_poses))\n",
        "position_diff = np.sqrt(np.sum((human_poses[:min_length, :2] - agent_poses[:min_length, :2])**2, axis=1))\n",
        "\n",
        "print(f\"\\nè½¨è¿¹å·®å¼‚åˆ†æ:\")\n",
        "print(f\"  - å¹³å‡ä½ç½®è¯¯å·®: {np.mean(position_diff):.2f}ç±³\")\n",
        "print(f\"  - æœ€å¤§ä½ç½®è¯¯å·®: {np.max(position_diff):.2f}ç±³\")\n",
        "print(f\"  - æœ€ç»ˆä½ç½®è¯¯å·®: {position_diff[-1]:.2f}ç±³\")\n",
        "\n",
        "# ç»˜åˆ¶ä½ç½®è¯¯å·®éšæ—¶é—´å˜åŒ–\n",
        "plt.figure(figsize=(12, 4))\n",
        "time_points = np.arange(min_length) * human_trajectory.trajectory_sampling.interval_length\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(time_points, position_diff, 'b-', linewidth=2)\n",
        "plt.xlabel('æ—¶é—´ (ç§’)')\n",
        "plt.ylabel('ä½ç½®è¯¯å·® (ç±³)')\n",
        "plt.title('ä½ç½®è¯¯å·®éšæ—¶é—´å˜åŒ–')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(human_poses[:, 0], human_poses[:, 1], 'g-', linewidth=3, label='äººç±»è½¨è¿¹', alpha=0.7)\n",
        "plt.plot(agent_poses[:, 0], agent_poses[:, 1], 'r--', linewidth=2, label='AIé¢„æµ‹')\n",
        "plt.scatter(human_poses[0, 0], human_poses[0, 1], c='green', s=100, marker='o', label='èµ·ç‚¹')\n",
        "plt.scatter(human_poses[-1, 0], human_poses[-1, 1], c='green', s=100, marker='s', label='ç»ˆç‚¹')\n",
        "plt.xlabel('Xåæ ‡ (ç±³)')\n",
        "plt.ylabel('Yåæ ‡ (ç±³)')\n",
        "plt.title('è½¨è¿¹å¯¹æ¯”ï¼ˆä¿¯è§†å›¾ï¼‰')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axis('equal')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. åˆ›å»ºå¢å¼ºå¯è§†åŒ–\n",
        "\n",
        "åŸºäºç°æœ‰ç»„ä»¶åˆ›å»ºç»¼åˆå¯è§†åŒ–ç•Œé¢\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_comprehensive_visualization(scene, agent):\n",
        "    \"\"\"\n",
        "    åˆ›å»ºç»¼åˆå¯è§†åŒ–ï¼Œå±•ç¤ºå¤šä¸ªè§’åº¦çš„åˆ†æç»“æœ\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    \n",
        "    # 1. BEVè½¨è¿¹å¯¹æ¯”ï¼ˆä¸»è¦è§†å›¾ï¼‰\n",
        "    ax1 = plt.subplot(2, 3, (1, 2))\n",
        "    \n",
        "    # å¤ç”¨ç°æœ‰çš„BEVå¯è§†åŒ–ç»„ä»¶\n",
        "    from navsim.visualization.bev import add_configured_bev_on_ax, add_trajectory_to_bev_ax\n",
        "    from navsim.visualization.config import TRAJECTORY_CONFIG\n",
        "    from navsim.visualization.plots import configure_bev_ax\n",
        "    \n",
        "    frame_idx = scene.scene_metadata.num_history_frames - 1\n",
        "    add_configured_bev_on_ax(ax1, scene.map_api, scene.frames[frame_idx])\n",
        "    \n",
        "    human_trajectory = scene.get_future_trajectory()\n",
        "    agent_trajectory = agent.compute_trajectory(scene.get_agent_input(), scene)\n",
        "    \n",
        "    add_trajectory_to_bev_ax(ax1, human_trajectory, TRAJECTORY_CONFIG[\"human\"])\n",
        "    add_trajectory_to_bev_ax(ax1, agent_trajectory, TRAJECTORY_CONFIG[\"agent\"])\n",
        "    configure_bev_ax(ax1)\n",
        "    ax1.set_title(f\"BEVè½¨è¿¹å¯¹æ¯” - {scene.scene_metadata.scenario_type}\")\n",
        "    \n",
        "    # 2. è¯¯å·®åˆ†æ\n",
        "    ax2 = plt.subplot(2, 3, 3)\n",
        "    human_poses = np.array(human_trajectory.poses)\n",
        "    agent_poses = np.array(agent_trajectory.poses)\n",
        "    min_length = min(len(human_poses), len(agent_poses))\n",
        "    \n",
        "    position_diff = np.sqrt(np.sum((human_poses[:min_length, :2] - agent_poses[:min_length, :2])**2, axis=1))\n",
        "    time_points = np.arange(min_length) * human_trajectory.trajectory_sampling.interval_length\n",
        "    \n",
        "    ax2.plot(time_points, position_diff, 'b-', linewidth=2)\n",
        "    ax2.set_xlabel('æ—¶é—´ (ç§’)')\n",
        "    ax2.set_ylabel('ä½ç½®è¯¯å·® (ç±³)')\n",
        "    ax2.set_title('è¯¯å·®éšæ—¶é—´å˜åŒ–')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. è½¨è¿¹ä¿¯è§†å›¾\n",
        "    ax3 = plt.subplot(2, 3, 4)\n",
        "    ax3.plot(human_poses[:, 0], human_poses[:, 1], 'g-', linewidth=3, label='äººç±»è½¨è¿¹', alpha=0.7)\n",
        "    ax3.plot(agent_poses[:, 0], agent_poses[:, 1], 'r--', linewidth=2, label='AIé¢„æµ‹')\n",
        "    ax3.scatter(human_poses[0, 0], human_poses[0, 1], c='green', s=100, marker='o')\n",
        "    ax3.set_xlabel('Xåæ ‡ (ç±³)')\n",
        "    ax3.set_ylabel('Yåæ ‡ (ç±³)')\n",
        "    ax3.set_title('è½¨è¿¹ä¿¯è§†å›¾')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    ax3.axis('equal')\n",
        "    \n",
        "    # 4. é€Ÿåº¦åˆ†æ\n",
        "    ax4 = plt.subplot(2, 3, 5)\n",
        "    if len(human_poses) > 1:\n",
        "        dt = human_trajectory.trajectory_sampling.interval_length\n",
        "        human_speeds = np.linalg.norm(np.diff(human_poses[:, :2], axis=0), axis=1) / dt\n",
        "        agent_speeds = np.linalg.norm(np.diff(agent_poses[:min_length, :2], axis=0), axis=1) / dt\n",
        "        \n",
        "        time_speed = time_points[1:min_length]\n",
        "        ax4.plot(time_speed, human_speeds[:len(time_speed)], 'g-', label='äººç±»é€Ÿåº¦', linewidth=2)\n",
        "        ax4.plot(time_speed, agent_speeds[:len(time_speed)], 'r--', label='AIé€Ÿåº¦', linewidth=2)\n",
        "        ax4.set_xlabel('æ—¶é—´ (ç§’)')\n",
        "        ax4.set_ylabel('é€Ÿåº¦ (m/s)')\n",
        "        ax4.set_title('é€Ÿåº¦å¯¹æ¯”')\n",
        "        ax4.legend()\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 5. ç»Ÿè®¡ä¿¡æ¯\n",
        "    ax5 = plt.subplot(2, 3, 6)\n",
        "    ax5.axis('off')\n",
        "    \n",
        "    stats_text = f\"\"\"\n",
        "åœºæ™¯ä¿¡æ¯:\n",
        "â€¢ Token: {scene.scene_metadata.token[:12]}...\n",
        "â€¢ ç±»å‹: {scene.scene_metadata.scenario_type}\n",
        "â€¢ æ—¥å¿—: {scene.scene_metadata.log_name}\n",
        "\n",
        "è½¨è¿¹ç»Ÿè®¡:\n",
        "â€¢ é¢„æµ‹æ—¶é•¿: {human_trajectory.trajectory_sampling.time_horizon:.1f}ç§’\n",
        "â€¢ é‡‡æ ·é—´éš”: {human_trajectory.trajectory_sampling.interval_length:.2f}ç§’\n",
        "â€¢ è½¨è¿¹ç‚¹æ•°: {min_length}\n",
        "\n",
        "æ€§èƒ½æŒ‡æ ‡:\n",
        "â€¢ å¹³å‡è¯¯å·®: {np.mean(position_diff):.2f}m\n",
        "â€¢ æœ€å¤§è¯¯å·®: {np.max(position_diff):.2f}m\n",
        "â€¢ æœ€ç»ˆè¯¯å·®: {position_diff[-1]:.2f}m\n",
        "â€¢ æ¨¡å‹ç±»å‹: {agent.model_type.upper()}\n",
        "    \"\"\"\n",
        "    \n",
        "    ax5.text(0.05, 0.95, stats_text, transform=ax5.transAxes, fontsize=9,\n",
        "             verticalalignment='top', fontfamily='monospace',\n",
        "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return fig\n",
        "\n",
        "# åˆ›å»ºç»¼åˆå¯è§†åŒ–\n",
        "print(\"åˆ›å»ºç»¼åˆå¯è§†åŒ–ç•Œé¢...\")\n",
        "comprehensive_fig = create_comprehensive_visualization(scene, inference_agent)\n",
        "print(\"ç»¼åˆå¯è§†åŒ–å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. æ€»ç»“ä¸ä¸‹ä¸€æ­¥\n",
        "\n",
        "### âœ… æœ¬æ•™ç¨‹å·²å®Œæˆçš„åŠŸèƒ½ï¼š\n",
        "\n",
        "1. **æ¨¡å‹åŠ è½½ç³»ç»Ÿ**ï¼šåˆ›å»ºäº†çµæ´»çš„æ¨¡å‹åŒ…è£…å™¨ï¼Œæ”¯æŒDiffusionDriveå’ŒTransfuseræ¨¡å‹\n",
        "2. **æ•°æ®åŠ è½½**ï¼šè®¾ç½®äº†åœºæ™¯åŠ è½½å™¨ï¼Œå¯ä»¥å¤„ç†ä¸åŒçš„æ•°æ®é›†åˆ†å‰²\n",
        "3. **åŸºç¡€å¯è§†åŒ–**ï¼šå¤ç”¨äº†`plot_bev_with_agent`è¿›è¡Œè½¨è¿¹å¯¹æ¯”\n",
        "4. **è¯¦ç»†åˆ†æ**ï¼šå®ç°äº†è½¨è¿¹è¯¯å·®åˆ†æå’Œæ€§èƒ½ç»Ÿè®¡\n",
        "5. **ç»¼åˆå¯è§†åŒ–**ï¼šåˆ›å»ºäº†å¤šè§†è§’çš„åˆ†æç•Œé¢\n",
        "\n",
        "### ğŸš€ ä¸‹ä¸€æ­¥å¯ä»¥æ‰©å±•çš„åŠŸèƒ½ï¼š\n",
        "\n",
        "#### é«˜çº§å¯è§†åŒ–åŠŸèƒ½\n",
        "- **TransfuserCallbackå¯è§†åŒ–**ï¼šé›†æˆè®­ç»ƒæ—¶çš„è¯¦ç»†å¯è§†åŒ–ï¼ˆç›¸æœº+BEV+æ¿€å…‰é›·è¾¾ï¼‰\n",
        "- **PDM Scoreè¯„ä¼°**ï¼šæ·»åŠ å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡è®¡ç®—å’Œå¯è§†åŒ–\n",
        "- **åŠ¨æ€GIFç”Ÿæˆ**ï¼šåˆ›å»ºæ—¶é—´åºåˆ—çš„åŠ¨ç”»å¯è§†åŒ–\n",
        "- **å¤šæ¨¡å‹å¯¹æ¯”**ï¼šåŒæ—¶å¯¹æ¯”å¤šä¸ªä¸åŒæ¨¡å‹çš„æ€§èƒ½\n",
        "\n",
        "#### åˆ†ææ·±åº¦æ‰©å±•\n",
        "- **åœºæ™¯ç±»å‹åˆ†æ**ï¼šé’ˆå¯¹ä¸åŒé©¾é©¶åœºæ™¯çš„ä¸“é¡¹åˆ†æ\n",
        "- **å¤±è´¥æ¡ˆä¾‹è¯Šæ–­**ï¼šè‡ªåŠ¨è¯†åˆ«å’Œåˆ†æé¢„æµ‹å¤±è´¥çš„åœºæ™¯\n",
        "- **ä¸ç¡®å®šæ€§å¯è§†åŒ–**ï¼šå¦‚æœæ¨¡å‹æ”¯æŒï¼Œæ˜¾ç¤ºé¢„æµ‹çš„ä¸ç¡®å®šæ€§\n",
        "- **æ³¨æ„åŠ›æœºåˆ¶å¯è§†åŒ–**ï¼šå±•ç¤ºæ¨¡å‹çš„å†³ç­–å…³æ³¨ç‚¹\n",
        "\n",
        "#### äº¤äº’å¼åŠŸèƒ½\n",
        "- **åœºæ™¯æµè§ˆå™¨**ï¼šåˆ›å»ºäº¤äº’å¼ç•Œé¢é€‰æ‹©å’Œåˆ‡æ¢åœºæ™¯\n",
        "- **å‚æ•°è°ƒèŠ‚**ï¼šå®æ—¶è°ƒæ•´å¯è§†åŒ–å‚æ•°å’Œæ¨¡å‹è®¾ç½®\n",
        "- **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒå¤§è§„æ¨¡åœºæ™¯çš„æ‰¹é‡åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ\n",
        "\n",
        "### ğŸ“ ä½¿ç”¨è¯´æ˜\n",
        "\n",
        "1. **è®¾ç½®æ•°æ®è·¯å¾„**ï¼šä¿®æ”¹`OPENSCENE_DATA_ROOT`ç¯å¢ƒå˜é‡\n",
        "2. **åŠ è½½æ‚¨çš„æ¨¡å‹**ï¼šä¿®æ”¹`checkpoint_path`å˜é‡æŒ‡å‘æ‚¨çš„æ¨¡å‹æ–‡ä»¶\n",
        "3. **é€‰æ‹©æ•°æ®é›†**ï¼šå¯ä»¥ä¿®æ”¹`SPLIT`å˜é‡é€‰æ‹©ä¸åŒçš„æ•°æ®é›†ï¼ˆmini/test/trainvalï¼‰\n",
        "4. **è‡ªå®šä¹‰å¯è§†åŒ–**ï¼šåŸºäºæä¾›çš„å‡½æ•°æ¨¡æ¿åˆ›å»ºæ‚¨è‡ªå·±çš„å¯è§†åŒ–\n",
        "\n",
        "### ğŸ’¡ æç¤º\n",
        "\n",
        "- å¦‚æœæ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œæœ¬æ•™ç¨‹ä¼šè‡ªåŠ¨ä½¿ç”¨å¸¸é€Ÿåº¦åŸºçº¿æ¨¡å‹è¿›è¡Œæ¼”ç¤º\n",
        "- æ‰€æœ‰å¯è§†åŒ–å‡½æ•°éƒ½å¯ä»¥ä¿å­˜ä¸ºå›¾ç‰‡æ–‡ä»¶ï¼Œåªéœ€æ·»åŠ ä¿å­˜è·¯å¾„å‚æ•°\n",
        "- ä»£ç è®¾è®¡ä¸ºæ¨¡å—åŒ–ï¼Œæ–¹ä¾¿é›†æˆåˆ°æ‚¨è‡ªå·±çš„è¯„ä¼°æµç¨‹ä¸­\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ‰ æ¨¡å‹æ¨ç†ä¸å¯è§†åŒ–æ•™ç¨‹å®Œæˆï¼\")\n",
        "print(f\"\\nå½“å‰ä½¿ç”¨çš„æ¨¡å‹ç±»å‹: {inference_agent.model_type}\")\n",
        "print(f\"æµ‹è¯•çš„åœºæ™¯: {scene.scene_metadata.scenario_type}\")\n",
        "print(f\"åœºæ™¯token: {token}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ æ¥ä¸‹æ¥æ‚¨å¯ä»¥ï¼š\")\n",
        "print(\"1. ä¿®æ”¹checkpoint_pathåŠ è½½æ‚¨è‡ªå·±çš„æ¨¡å‹\")\n",
        "print(\"2. å°è¯•ä¸åŒçš„åœºæ™¯ï¼ˆé‡æ–°è¿è¡Œåœºæ™¯é€‰æ‹©cellï¼‰\")\n",
        "print(\"3. æ‰©å±•å¯è§†åŒ–åŠŸèƒ½\")\n",
        "print(\"4. é›†æˆPDM Scoreè¯„ä¼°\")\n",
        "print(\"5. åˆ›å»ºæ‰¹é‡åˆ†æè„šæœ¬\")\n",
        "\n",
        "print(\"\\nğŸ“š ç›¸å…³æ–‡ä»¶å’Œå‡½æ•°ï¼š\")\n",
        "print(\"- navsim/visualization/plots.py - åŸºç¡€å¯è§†åŒ–å‡½æ•°\")\n",
        "print(\"- navsim/agents/diffusiondrive/transfuser_callback.py - è®­ç»ƒæ—¶å¯è§†åŒ–\")\n",
        "print(\"- navsim/evaluate/pdm_score.py - è¯„ä¼°æŒ‡æ ‡è®¡ç®—\")\n",
        "print(\"- tutorial/tutorial_visualization.ipynb - åŸºç¡€å¯è§†åŒ–æ•™ç¨‹\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
